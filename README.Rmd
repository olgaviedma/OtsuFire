# **OtsuFire: Fire Mapping and Regeneration Assessment Toolkit**

**Authors:** Natalia Quintero, Olga Viedma, Hammadi Achour, and Jose Manuel Moreno

Automated tools to map fire scars using Landsat-based RBR/dNBR composites and Otsu thresholding. Supports large-area mosaics, polygonization, filtering, regeneration assessment, and validation workflows.

---

## üîß System Requirements

### üêç Python & GDAL

Several functions in `OtsuFire` call the GDAL Python script `gdal_polygonize.py`. To use these functions, ensure:

- **Python** is installed (e.g., via Anaconda or Miniconda).
- **GDAL** is installed in your Python environment:
  - Via **Conda**: `conda install -c conda-forge gdal`
  - Or via **pip**: `pip install gdal` (less recommended)
- You know the full paths to:
  - Your Python executable (`python.exe`)
  - The `gdal_polygonize.py` script (typically in `Scripts/` on Windows)

üîß **Example configuration:**

```r
python_exe <- "C:/ProgramData/anaconda3/python.exe"
gdal_polygonize_script <- "C:/ProgramData/anaconda3/Scripts/gdal_polygonize.py"

```

### üõ†Ô∏è GDAL Installation Guide

# Open Anaconda Prompt or CMD
conda install -c conda-forge gdal

# Check version
gdalinfo --version

# Confirm availability
where gdalinfo

### Optional: Create a Dedicated GDAL Environment

conda create --name gdal_env -c conda-forge gdal
conda activate gdal_env
gdalinfo --version

### Validate GDAL in Python

python

import osgeo.gdal
print(osgeo.gdal.__version__)

### ‚úÖ Additional Notes

- All input rasters must be projected and masked consistently.
- Functions support large-area mosaics, tiling, and region-specific thresholding.
- Always ensure gdal_polygonize.py is accessible and executable.

# Getting Started

## Installation
```{r , echo=TRUE, message=FALSE, warning=FALSE}
#The CRAN version:
install.packages("OtsuFire")

# The development version:
#install.packages("remotes")
library(remotes)
install_github("https://github.com/olgaviedma/OtsuFire", dependencies = TRUE)

```

## Libraries
```{r , echo=TRUE, message=FALSE, warning=FALSE}

# Load the OtsuFire package and dependencies
library(OtsuFire)
library(dplyr)
library(ggplot2)
library(sf)
library(terra)
library(glue)
library(purrr)
library(tools)
library(data.table)
library(histogram)
library(otsuSeg)
library(stats)

```

## üì• Download and Prepare Example Data from Zenodo

This package includes examples that require raster and vector data stored externally on Zenodo. These files are not included in the CRAN version of the package to avoid exceeding size limits.

The following code downloads and extracts a ZIP archive into a local folder called `ZENODO/exdata`, located in the root of your working directory. This folder is ignored by R during package build and check processes (via `.Rbuildignore`).

Once downloaded and extracted, the data can be used in examples throughout this README or in your local scripts.

The following script:

- Downloads the dataset from Zenodo (only if not already downloaded)
- Validates the download
- Extracts the content
- Places the extracted files in a consistent folder structure

## 0. Import data from ZENODO
```{r, echo=TRUE, message=FALSE, warning=FALSE}

library(httr)

# Step 1: Define URLs and Local Paths to download ZENODO database
zenodo_url <- "https://zenodo.org/records/15322380/files/DATA.zip?download=1"
output_dir <- "ZENODO/exdata"
zip_file <- file.path(output_dir, "DATA.zip")
temp_dir <- file.path(output_dir, "temp_extracted")


# Step 2: Create the output directory if it doesn't exist
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Step 3: Download the ZIP file if it doesn't already exist
if (!file.exists(zip_file)) {
  message("Downloading DATA.zip from Zenodo...")
  GET(zenodo_url, write_disk(zip_file, overwrite = TRUE))
} else {
  message("DATA.zip already exists. Skipping download.")
}

# Step 4: Validate the downloaded ZIP file
file_size <- file.info(zip_file)$size
if (is.na(file_size) || file_size < 1e6) {
  stop("Download failed: ZIP file is too small or empty!")
} else {
  message(paste("ZIP file size:", round(file_size / (1024 * 1024), 2), "MB"))
}

# Step 5: Extract the ZIP file to a temporary folder
message("Extracting the ZIP file to a temporary folder...")
unzip(zip_file, exdir = temp_dir, overwrite = TRUE)

# Step 6: Move contents to final output directory
if (file.exists(file.path(temp_dir, "DATA"))) {
  # If ZIP contains a "DATA" subfolder, move its contents
  message("Moving extracted contents to the DATA directory...")
  file.rename(from = file.path(temp_dir, "DATA"), to = output_dir)
} else {
  # Otherwise, move all extracted files directly
  message("Moving extracted files to the DATA directory...")
  file.rename(from = temp_dir, to = output_dir)
}

# Step 7: Clean up temporary folder
unlink(temp_dir, recursive = TRUE)

# Step 8: Verify the extracted files
message("Verifying the final structure of extracted files...")
extracted_files <- list.files(output_dir, recursive = TRUE)
if (length(extracted_files) == 0) {
  stop("Unzipping failed: No files were extracted.")
} else {
  message("Extraction successful. Files extracted:")
  print(extracted_files)
}

# Step 9: Preview of extracted files (optional)
message("First few extracted files:")
print(head(extracted_files))

```
## 1. Mosaic and Resample Raster Data
```{r mask and resample your composite raster, echo=TRUE, message=FALSE, warning=FALSE}

folder_path <- "C:/ZENODO/exdata"

mask_mosaic_raster (
folder_path = file.path(system.file("extdata", package = "OtsuFire")),
mask_shapefile = file.path(folder_path,"burneable_classes_def1_corine06_ETRS89.shp"),
gdalwarp_path = "C:/ProgramData/anaconda3/Library/bin/gdalwarp.exe")

```
## 2. Apply Otsu Thresholding to RBR Raster
```{r fire scars mapping by using Otsu thresholding, echo=TRUE, message=FALSE, warning=FALSE}

folder_path = file.path(system.file("extdata", package = "OtsuFire"))
raster_path = file.path(folder_path,"IBERIAN_MinMin_2012_all_year_mosaic_masked_res90m")
corine_raster_path = file.path(folder_path,"burneable_classes_def1_corine06_ETRS89.tif")

python_exe = "C:/ProgramData/anaconda3/python.exe"
gdal_polygonize_script = "C:/ProgramData/anaconda3/Scripts/gdal_polygonize.py"

process_otsu_rasters(
  raster_path = raster_path,
  output_dir = folder_path,
  otsu_thresholds = c(0, 50),
  use_original = FALSE,
  python_exe = python_exe,
  gdal_polygonize_script = gdal_polygonize_script,
  tile = TRUE,
  index_type = NULL,
  corine_raster_path = corine_raster_path,
  ecoregion_shapefile_path = NULL,
  min_otsu_threshold_value = 100
)
```
## 3. Calculate Polygon Metrics and Apply Geometric Filters
```{r Fire polygons metrics (area and shape) and filtering based on several thresholds, echo=TRUE, message=FALSE, warning=FALSE}

folder_path = file.path(system.file("extdata", package = "OtsuFire"))
burned_files <- list.files(folder_path, pattern = "burned_areas_2012_otsu_*.shp$", full.names = TRUE)

calculate_polygon_metrics(
  shapefile_paths = burned_files,
  output_dir = folder_path,
  area_min_ha = 10,
  bbox_h_min = NULL, #630
  mnbbx_wd_min = NULL, #820
  p_w_ratio_min = NULL, #4.49
  h_w_ratio_min = NULL, #0.25
)
```

## 4. Detect Regeneration Areas using Otsu Thresholding on Negative RBR
```{r Fire polygons metrics (area and shape) and filtering based on several thresholds, echo=TRUE, message=FALSE, warning=FALSE}

python_exe = "C:/ProgramData/anaconda3/python.exe"
gdal_polygonize_script = "C:/ProgramData/anaconda3/Scripts/gdal_polygonize.py"

folder_path = file.path(system.file("extdata", package = "OtsuFire"))

process_otsu_regenera(
  rbr_post = list(
    P1 = file.path(folder_path,"IBERIAN_MinMin_2013_all_year_mosaic_masked_res90m.tif"),
    P2 = file.path(folder_path,"IBERIAN_MinMin_2014_all_year_mosaic_masked_res90m")
  ),
  output_dir = folder_path,
  fire_year = 2012,
  rbr_date = file.path(folder_path,"IBERIAN_MinMin_2012_all_year_mosaic_masked_res90m.tif"),
  regen_year = c(1, 2),
  use_fixed_threshold = TRUE,
  fixed_threshold_value = -100,
  trim_percentiles = NULL,
  python_exe = "path/to/python.exe",
  gdal_polygonize_script = "path/to/gdal_polygonize.py"
)
```
## 5. Flag Burned Polygons as Regenerating or Not
```{r Assigns regeneration flags to burned area polygons based on their spatial overlap with post-fire regeneration polygons, echo=TRUE, message=FALSE, warning=FALSE}

folder_path = file.path(system.file("extdata", package = "OtsuFire"))

flag_otsu_regenera(
  burned_files = list.files(folder_path, pattern = "*_filt_area.shp$", full.names = TRUE),
  regenera_files = list.files(folder_path, pattern = "*_thresh100.shp$", full.names = TRUE),
  min_regen_ratio = 0.10,
  remove_no_regenera = TRUE,
  remove_condition = "year1_and_year2",
  all_years_vector = NULL, #c("P1", "P2")
  output_dir = folder_path
)
```

## 6. Extract DOY Statistics from Raster for Each Polygon
```{r Extracts Day-of-Year (DOY) values from from a Landsat composite), masked by burned area polygons, and computes per-polygon statistics, echo=TRUE, message=FALSE, warning=FALSE}

python_exe = "C:/ProgramData/anaconda3/python.exe"
gdal_polygonize_script = "C:/ProgramData/anaconda3/Scripts/gdal_polygonize.py"

folder_path = file.path(system.file("extdata", package = "OtsuFire"))
raster_path = file.path(folder_path,"IBERIAN_MinMin_2012_all_year_mosaic_masked_res90m.tif")

calculate_doy_flags(
  raster = terra::rast(raster_path),
  doy_band = 2,
  polygons_sf = list.files(folder_path, pattern = "*_rat*_filter.shp$", full.names = TRUE),
  output_dir = folder_path,
  year = 2012,
  doy_thresholds = c(10),
  polygonize = TRUE,
  stats = "mode",
  keep_all_polygons = TRUE,
  calc_percentiles = TRUE,
  percentiles = c(0.05, 0.25, 0.95),
  python_exe = python_exe,
  gdal_polygonize_script = gdal_polygonize_script
)
```
## 7. Validate Detected Burned Areas with Reference Data
```{r Extracts Day-of-Year (DOY) values from from a Landsat composite), masked by burned area polygons, and computes per-polygon statistics, echo=TRUE, message=FALSE, warning=FALSE}

python_exe = "C:/ProgramData/anaconda3/python.exe"
gdal_polygonize_script = "C:/ProgramData/anaconda3/Scripts/gdal_polygonize.py"

folder_path = file.path(system.file("extdata", package = "OtsuFire"))

polygons_sf <- list.files(
  burned_dir,
  pattern = glob2rx("burned_areas_2012_otsu_*_thr100_P1P2_rat*.shp"),
  full.names = TRUE
)

ref_shapefile = file.path(folder_path,"fires_2012.shp")
mask_shapefile = file.path(folder_path,"PORTUGAL_SHAPE.shp")
burnable_raster = file.path(folder_path,"burneable_mask_binary_corine06_ETRS89.tif")

validate_fire_maps(
  input_shapefile = polygons_sf,
  ref_shapefile = ref_shapefile,
  mask_shapefile = mask_shapefile,
  burnable_raster = burnable_raster,
  year_target = 2012,
  validation_dir = folder_path,
  binary_burnable = TRUE,
  burnable_classes = NULL,
  min_area_reference_ha = 2,
  buffer = 0,
  threshold_completely_detected = 90,
  force_reprocess_ref = TRUE,
  use_gdal = TRUE,
  python_exe = python_exe,
  gdal_polygonize_script = gdal_polygonize_script
)


```



